import streamlit as st
from PIL import Image
import numpy as np
import cv2

# Set up Streamlit app
st.set_page_config(page_title="Vision Wizard", page_icon="üßô‚Äç‚ôÇÔ∏è", layout="wide")

st.title("Vision Wizard üßô‚Äç‚ôÇÔ∏è‚ú®: Simplifying Computer Vision Tasks")

page = st.sidebar.radio("**üåê Select a Feature**", ["Home Page üè†", "Image Resizing üìèüîÑ", "Image Grayscale Conversion üåëüîÑ", "Edge Detection ‚úÇÔ∏èüîç", "Image Rotation üîÑ‚Ü™Ô∏è", "Image Cropping ‚úÇÔ∏èüñºÔ∏è", "Image Flipping ‚ÜîÔ∏èüîÑ", "Color Space Conversion üåàüîÑ", "Image Brightness/Contrast Adjustment ‚òÄÔ∏èüåë", "Image Blurring üå´Ô∏èüîÑ", "Histogram Equalization üìä‚ú®", "Face Detection üòäüîç", "Object Detection üì¶üîç"])

def clear_session_state():
    st.session_state.pop("input_method", None)
    st.session_state.pop("uploaded_file", None)
    st.session_state.pop("capture_image", None)
    st.session_state.pop("image", None)
    
def get_image_input():
    # Check if image is already in session state
    if 'image' not in st.session_state:
        st.session_state.image = None

    # Function to check image complexity
    def is_image_complex(image):
        img_array = np.array(image)
        return img_array.shape[0] * img_array.shape[1] > 10000 * 10000  # Example threshold

    # Function to check image size
    def is_file_size_ok(file):
        file.seek(0, 2)  # Move to end of file
        file_size = file.tell()
        file.seek(0, 0)  # Move back to start of file
        return file_size <= 10 * 1024 * 1024  # 10 MB limit

    # Choose input method
    input_method = st.radio("**Select Image Input Method:** üì∏",
                            ("üìÅ Upload Image", "üì∑ Capture Image", "üñºÔ∏è Use Example Image"))

    if input_method == "üìÅ Upload Image":
        uploaded_file = st.file_uploader("Choose an image üìÇ", type=["jpg", "jpeg", "png"])
        if st.button("üìÅ Submit Image"):
            if uploaded_file is not None:
                if not is_file_size_ok(uploaded_file):
                    st.error("‚ùå Uploaded image is too large. Please upload an image smaller than 10MB.")
                    return None
                try:
                    image = Image.open(uploaded_file)
                    if is_image_complex(image):
                        st.error("‚ùå Uploaded image is too complex to process. Please upload a simpler image.")
                        return None
                    st.session_state.image = image
                except Exception as e:
                    st.error(f"‚ùå An error occurred: {str(e)}")
                    return None
            else:
                st.error("‚ùå Error: Please upload an image.")

    elif input_method == "üñºÔ∏è Use Example Image":
        example_image_path = "example.jpg"  # Ensure this file is in the same directory
        try:
            image = Image.open(example_image_path)
            st.session_state.image = image
        except Exception as e:
            st.error(f"‚ùå An error occurred: {str(e)}")
            return None

    elif input_method == "üì∑ Capture Image":
        capture_image = st.camera_input("Capture an image")
        if st.button("üì∑ Submit Image"):
            if capture_image is not None:
                try:
                    image = Image.open(capture_image)
                    if is_image_complex(image):
                        st.error("‚ùå Captured image is too complex to process. Please capture a simpler image.")
                        return None
                    st.session_state.image = image
                except Exception as e:
                    st.error(f"‚ùå An error occurred: {str(e)}")
                    return None
            else:
                st.error("‚ùå Error: Please take a photo.")

    return st.session_state.image

face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

def detect_faces(image):
    # Convert PIL image to grayscale OpenCV image
    gray_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))
    return faces

config_path = "yolov3.cfg"
model_path = "yolov3.weights"
labels_path = "coco.names"

try:
    net = cv2.dnn.readNetFromDarknet(config_path, model_path)
    layer_names = net.getLayerNames()
    layer_names = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]
    labels = open(labels_path).read().strip().split("\n")
except cv2.error as e:
    st.error(f"Error loading YOLO model: {e}")
    st.stop()

def detect_objects(image):
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)
    net.setInput(blob)
    layer_outputs = net.forward(layer_names)
    
    boxes = []
    confidences = []
    classIDs = []

    for output in layer_outputs:
        for detection in output:
            scores = detection[5:]
            classID = np.argmax(scores)
            confidence = scores[classID]
            if confidence > 0.5:
                box = detection[0:4] * np.array([W, H, W, H])
                (centerX, centerY, width, height) = box.astype("int")
                x = int(centerX - (width / 2))
                y = int(centerY - (height / 2))
                boxes.append([x, y, int(width), int(height)])
                confidences.append(float(confidence))
                classIDs.append(classID)

    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)
    return boxes, confidences, classIDs, idxs
    
# List of pages to exclude the common input section
exclude_input_pages = ["Home Page üè†"]

if page not in exclude_input_pages:
    # Common input section for pages not in the exclude list
    image = get_image_input()

    # Add a button to clear the session state
    if st.button("üóëÔ∏è Clear Input"):
        clear_session_state()
      
    st.info("‚ö†Ô∏è Click 'üóëÔ∏è Clear Input' to reset the image input fields. This will clear all entered data and allow you to start fresh.")

# Page 2
if page == "Image Resizing üìèüîÑ":
    st.header("üìèüîÑ Image Resizing Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        width, height = image.size
        st.subheader(f"**Original Image Dimensions:** {width} x {height}")
        new_width = st.number_input("New Width", value=width, min_value=1, max_value=6000)
        new_height = st.number_input("New Height", value=height, min_value=1, max_value=6000)
        resized_image = image.resize((new_width, new_height))
        if st.button("üîÑ Resize Image"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader('Resized Image')
            st.image(resized_image, caption='Resized Image', use_column_width=True)
            img_array = np.array(resized_image)
            resized_img = Image.fromarray(img_array)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 3
elif page == "Image Grayscale Conversion üåëüîÑ":
    st.header("üåëüîÑ Image Grayscale Conversion Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        if st.button("üåë Perform Grayscale Conversion"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("‚¨õ Grayscale Image") 
            img_array = np.array(image)
            gray_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
            st.image(gray_img, caption='Grayscale Image', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")
        
# Page 4
elif page == "Edge Detection ‚úÇÔ∏èüîç":
    st.header("‚úÇÔ∏èüîç Edge Detection Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        method = st.radio("‚úÇÔ∏è **Select Edge Detection Method**", ["Canny", "Sobel", "Laplacian"])
        opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        if method == "Canny":
            threshold1 = st.slider("Threshold 1", 0, 255, 100)
            threshold2 = st.slider("Threshold 2", 0, 255, 200)
            edges = cv2.Canny(opencv_image, threshold1, threshold2)
        elif method == "Sobel":
            dx = st.slider("dx", 0, 1, 1)
            dy = st.slider("dy", 0, 1, 1)
            ksize = st.slider("Kernel Size (must be odd)", 1, 31, 3, step=2)
            edges = cv2.Sobel(opencv_image, cv2.CV_64F, dx, dy, ksize=ksize)
            edges = cv2.convertScaleAbs(edges)  # Convert the result to uint8
        elif method == "Laplacian":
            ksize = st.slider("Kernel Size (must be odd)", 1, 31, 3, step=2)
            edges = cv2.Laplacian(opencv_image, cv2.CV_64F, ksize=ksize)
            edges = cv2.convertScaleAbs(edges)  # Convert the result to uint8
        if st.button("üîç Perform Edge Detection"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("üîç Image with Detected Edges") 
            st.image(edges, caption=f'Edges Detected using {method}', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 5
elif page == "Image Rotation üîÑ‚Ü™Ô∏è":
    st.header("üîÑ‚Ü™Ô∏è Image Rotation Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        angle = st.slider("Rotate Angle", min_value=0, max_value=360, value=0)
        if st.button("‚Ü™Ô∏è Rotate Image"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("üîÑ Rotated Image") 
            rotated_image = image.rotate(angle)
            st.image(rotated_image, caption=f'Image Rotated by {angle} degrees', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 6
elif page == "Image Cropping ‚úÇÔ∏èüñºÔ∏è":
    st.header("‚úÇÔ∏èüñºÔ∏è Image Cropping Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        width, height = image.size
        x = st.number_input("X Coordinate", value=0, min_value=0, max_value=width-1, step=1)
        y = st.number_input("Y Coordinate", value=0, min_value=0, max_value=height-1, step=1)
        max_crop_width = width - x
        max_crop_height = height - y
        new_width = st.number_input("Crop Width", value=max_crop_width, min_value=1, max_value=max_crop_width, step=1)
        new_height = st.number_input("Crop Height", value=max_crop_height, min_value=1, max_value=max_crop_height, step=1)
        if st.button("‚úÇÔ∏è Crop Image"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("‚úÇÔ∏è Cropped Image")
            cropped_image = image.crop((x, y, x + new_width, y + new_height))
            st.image(cropped_image, caption='Cropped Image', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 7
elif page == "Image Flipping ‚ÜîÔ∏èüîÑ":
    st.header("‚ÜîÔ∏èüîÑ Image Flipping Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        flip_option = st.radio("üîÑ **Flip Option**", ["Horizontal Flip", "Vertical Flip", "Diagonal Flip"])
        img_array = np.array(image)
        if flip_option == "Horizontal Flip":
            flipped_image = cv2.flip(img_array, 1)
        elif flip_option == "Diagonal Flip":
            flipped_image = image.transpose(Image.ROTATE_90).transpose(Image.FLIP_LEFT_RIGHT)
        else:
            flipped_image = cv2.flip(img_array, 0)
        if st.button("‚ÜîÔ∏è Flip Image"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("‚ÜîÔ∏è Flipped Image")
            st.image(flipped_image, caption=f'Image with {flip_option}', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 8
elif page == "Color Space Conversion üåàüîÑ":
    st.header("üåàüîÑ Color Space Conversion Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        color_space = st.radio("üî¥üü¢üîµ **Color Space**", ["RGB", "HSV", "LAB", "HLS", "YCbCr"])
        img_array = np.array(image)
        if color_space == "HSV":
            converted_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)
        elif color_space == "LAB":
            converted_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2LAB)
        elif color_space == "YCbCr":
            converted_img = image.convert("YCbCr")
        elif color_space == "HLS":
            converted_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2HLS)
            converted_img = Image.fromarray(converted_image)
        else:
            converted_img = img_array
        if st.button("üìü Convert Color Space"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("üåü Converted Image")
            st.image(converted_img, caption=f'Image in {color_space} Color Space', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 9
elif page == "Image Brightness/Contrast Adjustment ‚òÄÔ∏èüåë":
    st.header("‚òÄÔ∏èüåë Image Brightness/Contrast Adjustment Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        brightness = st.slider("Adjust Brightness", -100, 100, 0)
        contrast = st.slider("Adjust Contrast", -100, 100, 0)
        if st.button("‚òÄÔ∏è Adjust Brightness/Contrast"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("üì∑ Adjusted Image")
            opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            adjusted = cv2.convertScaleAbs(opencv_image, alpha=1 + contrast / 100, beta=brightness)
            st.image(adjusted, caption='Brightness/Contrast Adjusted Image', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 10
elif page == "Image Blurring üå´Ô∏èüîÑ":
    st.header("üå´Ô∏èüîÑ Image Blurring Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        blur_type = st.radio("üå´Ô∏è **Choose Blurring Effect**", ["Gaussian Blur", "Median Blur", "Bilateral Filter"])
        opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        if blur_type == "Gaussian Blur":
            ksize = st.slider("Kernel Size", min_value=1, max_value=50, value=5, step=2)
            blurred_image = cv2.GaussianBlur(opencv_image, (ksize, ksize), 0)
        elif blur_type == "Median Blur":
            ksize = st.slider("Kernel Size", min_value=1, max_value=50, value=5, step=2)
            if ksize % 2 == 0:
                ksize += 1  # Kernel size must be odd for median blur
            blurred_image = cv2.medianBlur(opencv_image, ksize)
        elif blur_type == "Bilateral Filter":
            d = st.slider("Diameter", min_value=1, max_value=50, value=9)
            sigmaColor = st.slider("Sigma Color", min_value=1, max_value=100, value=75)
            sigmaSpace = st.slider("Sigma Space", min_value=1, max_value=100, value=75)
            blurred_image = cv2.bilateralFilter(opencv_image, d, sigmaColor, sigmaSpace)
        if st.button("üìü Blur Image"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("üëì Blurred Image")
            blurred_image = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)
            blurred_image = Image.fromarray(blurred_image)
            st.image(blurred_image, caption=f'{blur_type} Applied', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 11
elif page == "Histogram Equalization üìä‚ú®":
    st.header("üìä‚ú® Histogram Equalization Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        if st.button("üìä Perform Histogram Equalization"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("‚ú® Histogram Equalized Image")
            img_array = np.array(image)
            gray_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)
            equalized_img = cv2.equalizeHist(gray_img)
            st.image(equalized_img, caption='Histogram Equalized Image', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

# Page 12
elif page == "Face Detection üòäüîç":
    st.header("üòäüîç Face Detection Feature")
    if "image" in st.session_state and st.session_state.image is not None:
        image = st.session_state.image
        if st.button("üòä Detect Faces"):
            st.subheader("üñºÔ∏è Original Image") 
            st.image(image, caption='Original Image', use_column_width=True)
            st.subheader("üîç Detected Faces")
            faces = detect_faces(image)
            if len(faces) == 0:
                st.error("‚ö†Ô∏è No faces detected in the image. Please try another image.")
            else:
                st.success(f"üòä Detected {len(faces)} face(s).")
                # Draw rectangles around the faces
                draw_image = np.array(image.copy())
                for (x, y, w, h) in faces:
                    cv2.rectangle(draw_image, (x, y), (x+w, y+h), (255, 0, 0), 2)
                st.image(draw_image, caption='Detected Faces', use_column_width=True)
    else:
        st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")

elif page == "Object Detection üì¶üîç" and image is not None:
    st.header("Object Detection üì¶üîç")
    opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    boxes, confidences, classIDs, idxs = detect_objects(opencv_image)

    if len(idxs) > 0:
        for i in idxs.flatten():
            (x, y) = (boxes[i][0], boxes[i][1])
            (w, h) = (boxes[i][2], boxes[i][3])
            color = [int(c) for c in np.random.randint(0, 255, size=(3,))]
            cv2.rectangle(opencv_image, (x, y), (x + w, y + h), color, 2)
            text = "{}: {:.4f}".format(labels[classIDs[i]], confidences[i])
            cv2.putText(opencv_image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    st.image(opencv_image, caption='Detected Objects', use_column_width=True)
else:
    st.info("‚ö†Ô∏è Please upload or capture an image, or use an example image.")
